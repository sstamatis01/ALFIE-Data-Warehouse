# Sharing Code with Partners - Key Information

## 🎯 Your Question Answered

**Q: Will partners running in separate Docker containers be able to reach Kafka, MongoDB, MinIO?**

**A: YES, but with important considerations:**

### ✅ What Works (Your Current Setup)
- You run DW services in Docker
- You run consumer scripts OUTSIDE Docker (on host machine)
- You use `localhost:9092` for Kafka, `localhost:8000` for API
- **This works because ports are exposed to host**

### ⚠️ What Changes (Partner in Docker)
- Partner runs their service IN Docker (separate container)
- **`localhost` won't work** - it refers to the container itself
- Must use **Docker service names** or **host networking**

---

## 🔑 Key Points for Partners

### 1. Network Configuration

**Option A: Docker Compose Network (Recommended)**
```yaml
# Partner's docker-compose.yml
services:
  agentic-core:
    image: partner/service:latest
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092     # ← Service name!
      API_BASE: http://dw-api:8000             # ← Service name!
    networks:
      - data-warehouse-network  # ← Join your network
```

**Option B: Host Networking (Simpler)**
```yaml
services:
  agentic-core:
    network_mode: "host"
    environment:
      KAFKA_BOOTSTRAP_SERVERS: localhost:9092  # ← localhost works!
      API_BASE: http://localhost:8000          # ← localhost works!
```

### 2. What Partners CAN Access

✅ **Kafka** - YES (needed for event-driven architecture)
- `kafka:29092` (inside Docker) or `localhost:9092` (outside Docker)

✅ **DW API** - YES (needed for data upload/download)
- `http://dw-api:8000` (inside Docker) or `http://localhost:8000` (outside Docker)

❌ **MongoDB** - NO (should use API instead)
- Direct access not recommended for security

❌ **MinIO** - NO (should use API instead)
- Direct access not recommended for security

---

## 📦 Files to Share with Partners

### Core Files
- ✅ `kafka_agentic_core_consumer_example.py` - Orchestrator template
- ✅ `kafka_bias_detector_consumer_example.py` - Bias detector template
- ✅ `kafka_automl_consumer_example.py` - AutoML template
- ✅ `kafka_xai_consumer_example.py` - XAI template

### Configuration
- ✅ `env.example.txt` - Environment variables template
- ✅ `docker-compose.partner-example.yml` - Docker compose example

### Documentation
- ✅ `DOCKER_DEPLOYMENT_GUIDE.md` - Complete networking guide
- ✅ `KAFKA_ORCHESTRATION_COMPLETE.md` - Complete Kafka flow
- ✅ `KAFKA_QUICK_REFERENCE.md` - Quick reference
- ✅ `API_CHANGES_USER_ID_AND_VERSIONING.md` - API documentation
- ✅ `PARTNER_INTEGRATION_CHECKLIST.md` - Integration checklist

### Optional (for reference)
- ✅ `TEST_COMPLETE_FLOW.md` - Testing guide
- ✅ `IMPLEMENTATION_SUMMARY.md` - Implementation details

---

## 🚀 Quick Start for Partners

### Step 1: Clone/Receive Code
```bash
# Partners receive the code package
git clone <your-repo>
cd data-warehouse-app
```

### Step 2: Set Up Environment
```bash
# Copy environment template
cp env.example.txt .env

# Edit with correct values
# For Docker: kafka:29092, http://dw-api:8000
# For local: localhost:9092, http://localhost:8000
nano .env
```

### Step 3: Choose Deployment Method

**Method A: Run on Host (Development)**
```bash
# Just run the script - uses localhost
python kafka_agentic_core_consumer_example.py
```

**Method B: Run in Docker (Production)**
```bash
# Build container
docker build -t partner/agentic-core .

# Run with network
docker run --network data-warehouse-network \
  -e KAFKA_BOOTSTRAP_SERVERS=kafka:29092 \
  -e API_BASE=http://dw-api:8000 \
  partner/agentic-core
```

---

## 🔒 Security Best Practices

### What Partners Should Do
✅ **Access DW only via API** - Don't directly connect to MongoDB/MinIO
✅ **Use dedicated Kafka consumer groups** - Don't conflict with other services
✅ **Handle errors gracefully** - Network issues, Kafka downtime, etc.
✅ **Use environment variables** - Don't hardcode connection strings
✅ **Implement retries** - For transient failures

### What Partners Should NOT Do
❌ **Don't directly access MongoDB** - Use API endpoints
❌ **Don't directly access MinIO** - Use API for file download
❌ **Don't hardcode hostnames** - Use environment variables
❌ **Don't expose sensitive data** - In logs or error messages
❌ **Don't skip error handling** - Services will fail

---

## 📋 Pre-Integration Checklist

Before partners start:

- [ ] **Understand the flow** - Read `KAFKA_ORCHESTRATION_COMPLETE.md`
- [ ] **Test connectivity** - Can reach Kafka and API
- [ ] **Review examples** - Understand consumer scripts
- [ ] **Configure environment** - Set up `.env` correctly
- [ ] **Test on host first** - Run scripts outside Docker
- [ ] **Then containerize** - Move to Docker after it works

---

## 🧪 Testing Connectivity

### Test 1: From Host Machine
```bash
# Test Kafka
nc -zv localhost 9092

# Test API
curl http://localhost:8000/health

# Run consumer
python kafka_agentic_core_consumer_example.py
```

### Test 2: From Docker Container
```bash
# Test Kafka
docker run --network data-warehouse-network nicolaka/netshoot \
  nc -zv kafka 29092

# Test API
docker run --network data-warehouse-network nicolaka/netshoot \
  curl http://dw-api:8000/health
```

---

## 💡 Common Questions

### Q: Do we need to install MongoDB/MinIO?
**A: NO!** You provide these services. Partners only need:
- Kafka client library (aiokafka)
- HTTP client (requests)
- Their business logic

### Q: Can partners modify the DW code?
**A: NO!** DW code is yours. Partners only:
- Use the consumer examples as templates
- Implement their own services
- Call your API endpoints

### Q: What if partners want direct database access?
**A: Discourage it!** Direct access means:
- Security risks
- No API audit trail
- Tight coupling
- Harder to upgrade

If absolutely necessary, document that it's NOT recommended.

### Q: What ports need to be exposed?
**A: Only these:**
- Kafka: 9092 (for external access)
- DW API: 8000 (for external access)
- MongoDB: Keep INTERNAL only
- MinIO: Keep INTERNAL only

---

## 📊 Current vs Partner Architecture

### Current (Your Development Setup)
```
┌─────────────────────────────────────┐
│  Docker (Your Machine)              │
│  ┌──────┐ ┌──────┐ ┌───────┐       │
│  │Kafka │ │Mongo │ │ DW API│       │
│  └──┬───┘ └──────┘ └───┬───┘       │
│     │                   │           │
│     │ Ports exposed     │           │
│     │ :9092, :8000      │           │
└─────┼───────────────────┼───────────┘
      │                   │
┌─────┼───────────────────┼───────────┐
│     │  Host Machine     │           │
│     │  (Your Terminal)  │           │
│  ┌──▼────────────────────▼─────┐   │
│  │  Consumer Scripts           │   │
│  │  - Uses localhost:9092      │   │
│  │  - Uses localhost:8000      │   │
│  └─────────────────────────────┘   │
└─────────────────────────────────────┘
```

### Partner Setup (Production)
```
┌─────────────────────────────────────────┐
│  Docker Network: data-warehouse-network │
│                                         │
│  ┌──────┐ ┌──────┐ ┌───────┐          │
│  │Kafka │ │Mongo │ │ DW API│          │
│  └──┬───┘ └──────┘ └───┬───┘          │
│     │                   │              │
│     │ Internal network  │              │
│     │ kafka:29092       │              │
└─────┼───────────────────┼──────────────┘
      │                   │
┌─────┼───────────────────┼──────────────┐
│     │  Partner Container│              │
│  ┌──▼────────────────────▼─────┐      │
│  │  Partner Service            │      │
│  │  - Uses kafka:29092         │      │
│  │  - Uses dw-api:8000         │      │
│  └─────────────────────────────┘      │
└─────────────────────────────────────────┘
```

---

## ✅ Summary

**Your Question: Can partners reach Kafka, MongoDB, MinIO from separate Docker containers?**

**Answer:**

1. **Kafka: YES** ✅
   - Use `kafka:29092` (inside Docker) or `localhost:9092` (outside Docker)
   - Needed for event-driven architecture

2. **DW API: YES** ✅
   - Use `http://dw-api:8000` (inside Docker) or `http://localhost:8000` (outside Docker)
   - Needed for data upload/download

3. **MongoDB: NOT RECOMMENDED** ⚠️
   - CAN access if on same network: `mongodb:27017`
   - But SHOULD use API instead for security

4. **MinIO: NOT RECOMMENDED** ⚠️
   - CAN access if on same network: `minio:9000`
   - But SHOULD use API instead for security

**Key Point:** Your current setup (running scripts on host) works perfectly! Partners will need to adjust hostnames when containerizing, but the logic stays the same.

---

## 📦 Package to Share

Create a partner package:

```bash
# Create partner package directory
mkdir data-warehouse-partner-package
cd data-warehouse-partner-package

# Copy essential files
cp kafka_*_consumer_example.py .
cp env.example.txt .
cp docker-compose.partner-example.yml .
cp *_README.md .
cp *_GUIDE.md .
cp PARTNER_INTEGRATION_CHECKLIST.md .

# Create README
cat > README.md << 'EOF'
# Data Warehouse Integration Package

## Quick Start
1. Read DOCKER_DEPLOYMENT_GUIDE.md
2. Copy env.example.txt to .env
3. Configure your environment
4. Test consumer scripts
5. Containerize when ready

## Support
Contact: your-email@example.com
EOF

# Create archive
tar -czf data-warehouse-partner-package.tar.gz .
```

---

## 🎉 You're Ready!

Everything partners need is documented and ready to share. The key points:

✅ Consumer scripts work as-is (just change hostnames for Docker)
✅ Network configuration is well-documented
✅ Security best practices included
✅ Testing guides provided
✅ Complete examples available

**Your current setup proves it works - partners just need to adjust for Docker networking!** 🚀

