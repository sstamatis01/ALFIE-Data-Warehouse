# XAI Consumer V2 - Complete Analysis

## üìã **Overview**

`kafka_xai_consumer_example_v2.py` is a **full-featured XAI (Explainable AI) service** that generates real explainability reports using SHAP, matplotlib, and machine learning analysis. This is a significant upgrade from the simple dummy version.

---

## üéØ **What It Does**

### **Core Functionality:**

1. **Listens to XAI trigger events** from Kafka (`xai-trigger-events` topic)
2. **Downloads dataset and model** from the Data Warehouse
3. **Generates real XAI explanations** using:
   - **SHAP (SHapley Additive exPlanations)** for feature importance
   - **Model predictions** and classification metrics
   - **Fairness analysis** across demographic groups
   - **Data analysis** with clustering and anomaly detection
4. **Creates HTML reports** with embedded visualizations (charts, graphs)
5. **Uploads reports** to Data Warehouse (triggers `xai-events`)

### **Key Features:**

- ‚úÖ **Real SHAP analysis** - Uses TreeExplainer for model interpretability
- ‚úÖ **Visualizations** - Generates matplotlib/seaborn charts embedded in HTML
- ‚úÖ **Model loading** - Loads actual trained models (`.pkl` files) with joblib
- ‚úÖ **Label encoders** - Handles models with separate encoder files
- ‚úÖ **Fairness metrics** - Computes accuracy, precision, recall per demographic group
- ‚úÖ **Anomaly detection** - Z-score analysis for unusual patterns
- ‚úÖ **Clustering** - KMeans clustering for driver state classification
- ‚úÖ **Beginner & Expert reports** - Two levels of explanation detail

---

## üì¶ **Required Dependencies**

### **Missing from requirements.txt:**

The following packages are **NOT** in `requirements.txt` but are required by v2:

```python
shap          # SHAP library for model explainability
matplotlib    # For generating charts and plots
seaborn       # For statistical visualizations
joblib        # For loading .pkl model files
```

### **Already in requirements.txt:**

```python
pandas==2.1.4           # ‚úÖ Data manipulation
numpy==1.26.2           # ‚úÖ Numerical operations
scikit-learn==1.3.2     # ‚úÖ ML models and metrics
scipy==1.11.4           # ‚úÖ Statistical functions (zscore)
aiokafka==0.8.0         # ‚úÖ Kafka consumer
requests==2.31.0        # ‚úÖ HTTP requests
```

### **Complete Dependency List for V2:**

```txt
# Core dependencies (already in requirements.txt)
fastapi==0.104.1
uvicorn==0.24.0
pymongo==4.6.0
motor==3.3.2
minio==7.2.0
pydantic==2.5.0
python-multipart==0.0.6
pandas==2.1.4
python-dotenv==1.0.0
pydantic-settings==2.1.0
passlib==1.7.4
python-jose==3.3.0
bcrypt==4.1.2
aiofiles==23.2.1
aiokafka==0.8.0
kafka-python==2.0.2
pydantic[email]==2.5.0
aiohttp==3.9.1
openpyxl==3.1.2
numpy==1.26.2
scikit-learn==1.3.2
scipy==1.11.4
imbalanced-learn==0.11.0
river==0.21.0
requests==2.31.0

# ADDITIONAL dependencies needed for V2:
shap>=0.43.0           # ‚ö†Ô∏è MISSING - Required for SHAP explainability
matplotlib>=3.7.0      # ‚ö†Ô∏è MISSING - Required for chart generation
seaborn>=0.12.0        # ‚ö†Ô∏è MISSING - Required for statistical plots
joblib>=1.3.0          # ‚ö†Ô∏è MISSING - Required for loading .pkl models
```

---

## üîç **What V2 Does Differently from Simple Version**

| Feature | Simple Version (`kafka_xai_consumer_example.py`) | V2 (`kafka_xai_consumer_example_v2.py`) |
|---------|--------------------------------------------------|------------------------------------------|
| **XAI Generation** | ‚ùå Uses dummy HTML files | ‚úÖ Generates real SHAP explanations |
| **Model Loading** | ‚ùå Doesn't load models | ‚úÖ Loads actual .pkl models with joblib |
| **Visualizations** | ‚ùå No charts | ‚úÖ Generates matplotlib/seaborn charts |
| **SHAP Analysis** | ‚ùå Not used | ‚úÖ Full SHAP TreeExplainer analysis |
| **Fairness Metrics** | ‚ùå Not computed | ‚úÖ Computes per-group accuracy/precision/recall |
| **Data Analysis** | ‚ùå Basic | ‚úÖ Clustering, anomaly detection, correlation |
| **Report Quality** | ‚ö†Ô∏è Placeholder | ‚úÖ Production-ready HTML reports |
| **Dependencies** | ‚úÖ All in requirements.txt | ‚ö†Ô∏è Needs shap, matplotlib, seaborn, joblib |

---

## üê≥ **Docker Container Requirements**

### **Does It Need a Separate Docker Container?**

**Answer: It depends on your deployment strategy:**

#### **Option 1: Same Container (Recommended for Development)**
- ‚úÖ Can run in the same container as the API/bias-detector
- ‚úÖ Shares the same Python environment
- ‚úÖ Simpler deployment
- ‚ö†Ô∏è Requires adding missing dependencies to `requirements.txt`
- ‚ö†Ô∏è Larger container image (includes ML libraries)

#### **Option 2: Separate Container (Recommended for Production)**
- ‚úÖ Isolated service - XAI failures don't affect API
- ‚úÖ Can scale independently
- ‚úÖ Smaller base image for API container
- ‚úÖ Can use GPU-enabled image for SHAP (if needed)
- ‚ö†Ô∏è More complex docker-compose setup
- ‚ö†Ô∏è Need to manage separate dependencies

---

## üîß **Current Issues with V2**

### **1. Missing Version Support** ‚ö†Ô∏è

The v2 file **does NOT** have the versioning updates we just added:
- ‚ùå Doesn't extract `dataset_version` from Kafka events
- ‚ùå Doesn't extract `model_version` from Kafka events
- ‚ùå Doesn't pass versions to API endpoints
- ‚ùå Uses old event structure (no `input` wrapper)

### **2. Missing Dependencies** ‚ö†Ô∏è

The following are not in `requirements.txt`:
- `shap`
- `matplotlib`
- `seaborn`
- `joblib`

### **3. Event Structure Mismatch** ‚ö†Ô∏è

V2 expects old event format:
```python
user_id = event.get("user_id")  # ‚ùå Should be event.get("input", {}).get("user_id")
```

But Agentic Core now sends:
```json
{
  "input": {
    "user_id": "...",
    "dataset_version": "v1",
    "model_version": "v1"
  }
}
```

---

## üìù **Recommendations**

### **1. Update requirements.txt**

Add missing dependencies:
```txt
shap>=0.43.0
matplotlib>=3.7.0
seaborn>=0.12.0
joblib>=1.3.0
```

### **2. Add Version Support to V2**

Update `kafka_xai_consumer_example_v2.py` to:
- Extract `input` object from Kafka events
- Get `dataset_version` and `model_version` from input
- Pass versions to all API calls
- Update `upload_xai_report()` to include versions

### **3. Docker Strategy**

**For Development:**
- Add missing dependencies to main `requirements.txt`
- Run v2 in same container or as separate service in docker-compose
- Update Dockerfile to include visualization libraries

**For Production:**
- Create separate Dockerfile for XAI service
- Use lighter base image + ML libraries
- Scale independently based on XAI workload

---

## üöÄ **Quick Fix: Add Missing Dependencies**

Add to `requirements.txt`:
```txt
shap>=0.43.0
matplotlib>=3.7.0
seaborn>=0.12.0
joblib>=1.3.0
```

---

## üîÑ **Docker Compose Integration**

If you want to add v2 to docker-compose, you could add:

```yaml
  # XAI Consumer Service (V2 - Full SHAP Analysis)
  xai-consumer-v2:
    build: .
    env_file:
      - .env
    container_name: data-warehouse-xai-consumer-v2
    restart: unless-stopped
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_XAI_TRIGGER_TOPIC: xai-trigger-events
      KAFKA_XAI_CONSUMER_GROUP: xai-consumer-v2
      API_BASE: http://api:8000
    depends_on:
      api:
        condition: service_started
      kafka:
        condition: service_healthy
    networks:
      - data-warehouse-network
    command: >
      sh -c "sleep 20 && python kafka_xai_consumer_example_v2.py"
    volumes:
      - ./app:/app/app:ro
      - ./kafka_xai_consumer_example_v2.py:/app/kafka_xai_consumer_example_v2.py:ro
      - ./xai-model:/app/xai-model:ro  # If model files are needed
```

---

## ‚úÖ **Summary**

**V2 is a production-ready XAI service** that:
- ‚úÖ Generates real SHAP explanations
- ‚úÖ Creates visual HTML reports
- ‚úÖ Performs fairness analysis
- ‚úÖ Handles real model files

**But it needs:**
- ‚ö†Ô∏è Missing dependencies added to requirements.txt
- ‚ö†Ô∏è Version support added (like we did for simple version)
- ‚ö†Ô∏è Event structure updated to match new Kafka format

**Docker decision:**
- **Same container**: Simpler, good for dev
- **Separate container**: Better for production, allows independent scaling





