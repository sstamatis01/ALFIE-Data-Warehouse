# Dataset Folder Upload - Complete Implementation

## âœ… Implementation Complete

Full support for folder uploads with multiple files, including upload, download, delete, and file listing operations.

---

## ğŸ¯ Features Implemented

### 1. Upload Folder âœ…
- **Endpoint**: `POST /datasets/upload/folder/{user_id}`
- Upload ZIP archives with multiple files
- Auto-versioning (v1, v2, v3, etc.)
- Simplified metadata (no content analysis)
- Kafka event integration

### 2. Download Folder âœ…
- **Endpoint**: `GET /datasets/{user_id}/{dataset_id}/download`
- Download entire folder as ZIP
- Download specific file by filename
- Version-specific downloads supported

### 3. Delete Folder âœ…
- **Endpoint**: `DELETE /datasets/{user_id}/{dataset_id}`
- Delete all files in folder
- Delete all versions
- Cascade delete (files + metadata)

### 4. List Files âœ…
- **Endpoint**: `GET /datasets/{user_id}/{dataset_id}/files`
- List all files in folder
- Shows sizes, types, hashes
- Version-specific listing supported

---

## ğŸ“Š Single File vs Folder Upload

| Feature | Single File | Folder |
|---------|-------------|--------|
| **Endpoint** | `/upload/{user_id}` | `/upload/folder/{user_id}` |
| **Input** | Single file | ZIP archive |
| **Metadata** | Full (columns, rows, types) | Simplified (file list) |
| **Download** | Direct file | ZIP or specific file |
| **Delete** | Single file | All files in folder |
| **List Files** | Single item | All files |

---

## ğŸš€ Quick Start

### Upload Folder

```bash
# Create ZIP
zip -r dataset.zip file1.csv file2.json metadata.txt

# Upload
curl -X POST "http://localhost:8000/datasets/upload/folder/user123" \
  -F "zip_file=@dataset.zip" \
  -F "dataset_id=my-dataset" \
  -F "name=My Dataset"
```

### List Files

```bash
curl "http://localhost:8000/datasets/user123/my-dataset/files" | jq
```

### Download Specific File

```bash
curl -o file1.csv \
  "http://localhost:8000/datasets/user123/my-dataset/download?filename=file1.csv"
```

### Download Entire Folder

```bash
curl -o my-dataset.zip \
  "http://localhost:8000/datasets/user123/my-dataset/download"
```

### Delete Dataset

```bash
curl -X DELETE "http://localhost:8000/datasets/user123/my-dataset"
```

---

## ğŸ’» Python Example

```python
import requests
import zipfile

API_BASE = "http://localhost:8000"

# 1. Create ZIP
with zipfile.ZipFile('dataset.zip', 'w') as zipf:
    zipf.write('data1.csv')
    zipf.write('data2.csv')
    zipf.write('metadata.json')

# 2. Upload folder
with open('dataset.zip', 'rb') as f:
    files = {'zip_file': f}
    data = {
        'dataset_id': 'test-folder',
        'name': 'Test Folder Dataset'
    }
    response = requests.post(
        f"{API_BASE}/datasets/upload/folder/user123",
        files=files,
        data=data
    )
    print(f"Uploaded: {response.json()['version']}")

# 3. List files
response = requests.get(f"{API_BASE}/datasets/user123/test-folder/files")
files = response.json()
print(f"Files: {[f['filename'] for f in files]}")

# 4. Download specific file
response = requests.get(
    f"{API_BASE}/datasets/user123/test-folder/download",
    params={"filename": "data1.csv"}
)
with open("downloaded.csv", "wb") as f:
    f.write(response.content)

# 5. Download entire folder
response = requests.get(f"{API_BASE}/datasets/user123/test-folder/download")
with open("downloaded_folder.zip", "wb") as f:
    f.write(response.content)

# 6. Delete dataset
response = requests.delete(f"{API_BASE}/datasets/user123/test-folder")
print(f"Deleted: {response.json()}")
```

---

## ğŸ“‹ Files Modified

### Backend Code
- âœ… `app/models/dataset.py` - Added DatasetFile, folder support
- âœ… `app/services/file_service.py` - Added folder operations
- âœ… `app/api/datasets.py` - Added folder endpoints

### Testing & Documentation
- âœ… `test_dataset_folder_operations.py` - Complete test script
- âœ… `Documentation/DATASET_FOLDER_UPLOAD.md` - Upload documentation
- âœ… `Documentation/DATASET_DOWNLOAD_DELETE.md` - Download/delete documentation
- âœ… `Documentation/DATASET_FOLDER_COMPLETE.md` - This summary

---

## ğŸ” API Endpoints

### Upload
```
POST /datasets/upload/{user_id}              # Single file
POST /datasets/upload/folder/{user_id}       # Folder (ZIP)
```

### Download
```
GET /datasets/{user_id}/{dataset_id}/download
    ?filename={filename}  # Optional: specific file

GET /datasets/{user_id}/{dataset_id}/version/{version}/download
    ?filename={filename}  # Optional: specific file
```

### List Files
```
GET /datasets/{user_id}/{dataset_id}/files
    ?version={version}    # Optional: specific version
```

### Delete
```
DELETE /datasets/{user_id}/{dataset_id}              # All versions
DELETE /datasets/{user_id}/{dataset_id}/version/{version}  # Specific version
```

---

## âš™ï¸ Technical Implementation

### Folder Upload
```python
# Extract ZIP â†’ Upload each file â†’ Store metadata
dataset_files, total_size = await file_service.upload_dataset_folder(
    zip_file=zip_file,
    user_id=user_id,
    dataset_id=dataset_id,
    version=version,
    preserve_structure=True
)
```

### Folder Download
```python
# List files â†’ Create ZIP â†’ Stream response
zip_data = await file_service.download_folder_as_zip(folder_path)
return StreamingResponse(BytesIO(zip_data), media_type='application/zip')
```

### Folder Delete
```python
# List files â†’ Delete each file â†’ Remove metadata
deleted_count = await file_service.delete_folder_files(folder_path)
```

---

## ğŸ¯ Metadata Differences

### Single File Metadata
```json
{
  "is_folder": false,
  "file_type": "csv",
  "file_size": 1024,
  "original_filename": "data.csv",
  "columns": ["col1", "col2"],
  "row_count": 100,
  "data_types": {"col1": "int64"},
  "files": null
}
```

### Folder Metadata
```json
{
  "is_folder": true,
  "file_type": "csv, json, txt",
  "file_size": 5120,
  "original_filename": "dataset.zip",
  "columns": null,
  "row_count": null,
  "data_types": null,
  "files": [
    {
      "filename": "data1.csv",
      "file_path": "datasets/user123/dataset1/v1/data1.csv",
      "file_size": 2048,
      "file_type": "csv",
      "file_hash": "abc123..."
    },
    {
      "filename": "data2.csv",
      "file_path": "datasets/user123/dataset1/v1/data2.csv",
      "file_size": 2048,
      "file_type": "csv",
      "file_hash": "def456..."
    }
  ],
  "custom_metadata": {
    "file_count": 2,
    "preserve_structure": true
  }
}
```

---

## âœ… Design Decisions

Per your requirements:

1. **Single file**: Full metadata extraction âœ…
   - Columns, rows, data types analyzed
   - Automatic detection of structure

2. **Folder**: Simplified metadata âœ…
   - Only file inventory (names, sizes, types)
   - No content analysis (faster)
   - No CSV parsing or column detection

3. **Download flexibility**: âœ…
   - Download entire folder as ZIP
   - OR download specific file by name
   - Same pattern as AI models

4. **Delete properly**: âœ…
   - Single file: Delete one file
   - Folder: Delete all files recursively
   - Cascade delete metadata

---

## ğŸ§ª Testing

Run the complete test suite:

```bash
python test_dataset_folder_operations.py
```

Expected output:
```
ğŸ“ Creating test files...
âœ… Created test files and ZIP

1ï¸âƒ£ Testing Folder Upload
âœ… Folder uploaded successfully!
   Version: v1
   Is folder: True
   File count: 3

2ï¸âƒ£ Testing List Files
âœ… Found 3 files:
   - test_data1.csv (35 bytes, csv)
   - test_data2.csv (38 bytes, csv)
   - test_metadata.json (XX bytes, json)

3ï¸âƒ£ Testing Download Specific File: test_data1.csv
âœ… Downloaded test_data1.csv (35 bytes)

4ï¸âƒ£ Testing Download Folder as ZIP
âœ… Downloaded folder as ZIP (XXX bytes)
   Files in ZIP: 3

5ï¸âƒ£ Testing Delete Dataset
âœ… Deleted successfully!
   Files deleted: 3
âœ… Verified: Dataset no longer exists

âœ… All tests completed!
```

---

## ğŸ‰ Summary

**Complete folder support for datasets:**
- âœ… Upload multiple files as ZIP
- âœ… Simplified metadata (per your specs)
- âœ… Download entire folder or specific files
- âœ… Delete folder with all files
- âœ… List files in folder
- âœ… Full versioning support
- âœ… Kafka event integration
- âœ… Backward compatible with single files

**Feature parity with AI models:**
- âœ… Same upload pattern
- âœ… Same download pattern  
- âœ… Same delete pattern
- âœ… Same file listing

The dataset API now has complete folder support! ğŸš€

